{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c175829b-ade5-4c05-b639-8062860b639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 13:03:51.937128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b198bde-3c03-4817-a92c-2a8f2e75ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train= tfds.load(name='fashion_mnist', split='train')\n",
    "mnist_test= tfds.load(name='fashion_mnist', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8004e040-32f1-4360-b6c4-baf0cade8e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7919fa2f-fba1-49c0-a174-e5e21da986b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f35452-ec65-4c1c-aee1-cefc60ec94e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='fashion_mnist',\n",
      "    full_name='fashion_mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
      "    data_dir='/Users/jasonmiller/tensorflow_datasets/fashion_mnist/3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=29.45 MiB,\n",
      "    dataset_size=36.42 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
      "      author    = {Han Xiao and\n",
      "                   Kashif Rasul and\n",
      "                   Roland Vollgraf},\n",
      "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
      "                   Algorithms},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1708.07747},\n",
      "      year      = {2017},\n",
      "      url       = {http://arxiv.org/abs/1708.07747},\n",
      "      archivePrefix = {arXiv},\n",
      "      eprint    = {1708.07747},\n",
      "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
      "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data, info = tfds.load('fashion_mnist', with_info=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69da079a-cc14-45b5-b92a-226783c9153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = tfds.load(\n",
    "    'fashion_mnist', split=['train','test'], batch_size=-1, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd6d6c0-45b5-4b12-be0b-38dd68d31415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(type(train_images))\n",
    "print(type(train_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6871273f-99c2-4b01-81bd-fb96ecbb8e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one row of grayscale pixel values\n",
      "tf.Tensor(\n",
      "[[  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 26]\n",
      " [ 92]\n",
      " [ 69]\n",
      " [ 68]\n",
      " [ 75]\n",
      " [ 75]\n",
      " [ 71]\n",
      " [ 74]\n",
      " [ 83]\n",
      " [ 75]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 74]\n",
      " [ 74]\n",
      " [ 83]\n",
      " [ 77]\n",
      " [108]\n",
      " [ 34]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]], shape=(28, 1), dtype=uint8)\n",
      "same row of normalized pixel values\n",
      "tf.Tensor(\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.10196079]\n",
      " [0.36078432]\n",
      " [0.27058825]\n",
      " [0.26666668]\n",
      " [0.29411766]\n",
      " [0.29411766]\n",
      " [0.2784314 ]\n",
      " [0.2901961 ]\n",
      " [0.3254902 ]\n",
      " [0.29411766]\n",
      " [0.3019608 ]\n",
      " [0.30588236]\n",
      " [0.2901961 ]\n",
      " [0.2901961 ]\n",
      " [0.3254902 ]\n",
      " [0.3019608 ]\n",
      " [0.42352942]\n",
      " [0.13333334]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]], shape=(28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image1 = train_images[0]\n",
    "print('one row of grayscale pixel values')\n",
    "print(image1[3])\n",
    "\n",
    "normalizer = tf.cast(255,tf.float32)\n",
    "norm_images = tfds.as_numpy(train_images)/normalizer\n",
    "\n",
    "image1 = norm_images[0]\n",
    "print('same row of normalized pixel values')\n",
    "print(image1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6a99e4-1cef-40aa-8118-6e7c713bdd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image,label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a443ceb8-eef6-4699-89ba-d442d033f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n",
      "(28, 28, 1) label 2\n",
      "(28, 28, 1) label 1\n",
      "(28, 28, 1) label 8\n",
      "(28, 28, 1) label 4\n",
      "(28, 28, 1) label 1\n",
      "(28, 28, 1) label 9\n",
      "(28, 28, 1) label 2\n",
      "(28, 28, 1) label 2\n",
      "(28, 28, 1) label 0\n",
      "(28, 28, 1) label 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 13:07:36.618089: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_set = tfds.load(\n",
    "    'fashion_mnist', split='train', as_supervised=True)\n",
    "#example = train_set[0]\n",
    "print(type(train_set))\n",
    "stop = 10\n",
    "for image, label in train_set:\n",
    "    if stop == 0:\n",
    "        break\n",
    "    stop -= 1\n",
    "    nimage = np.asarray(image)\n",
    "    value = int(label)\n",
    "    print(np.shape(nimage), 'label', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de06c8d1-9889-47f7-a25a-a2591a3dffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_set = train_set.map(augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58669632-3552-4dbf-b11d-2ca87cfe6431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
      "(28, 28, 1) label 2\n",
      "(28, 28, 1) label 1\n",
      "(28, 28, 1) label 8\n",
      "(28, 28, 1) label 4\n",
      "(28, 28, 1) label 1\n",
      "(28, 28, 1) label 9\n",
      "(28, 28, 1) label 2\n",
      "(28, 28, 1) label 2\n",
      "(28, 28, 1) label 0\n",
      "(28, 28, 1) label 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 13:08:45.864104: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "print(type(augmented_set))\n",
    "stop = 10\n",
    "for image, label in augmented_set:\n",
    "    if stop == 0:\n",
    "        break\n",
    "    stop -= 1\n",
    "    nimage = np.asarray(image)\n",
    "    value = int(label)\n",
    "    print(np.shape(nimage), 'label', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51e9ea-bcd8-4780-b7c3-3d8520de8d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974f6f6-9591-4160-a4c7-98b0a416c757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
